# Desagio T2C

Este projeto √© um **scraper automatizado** que coleta informa√ß√µes de notebooks no site da Magazine Luiza, organiza os dados em uma planilha Excel e envia o arquivo por e-mail usando o servi√ßo **SendGrid**.

## üìÇ Estrutura do Projeto

| Tipo          | Item                       | Descri√ß√£o                          |
|---------------|----------------------------|------------------------------------|
| Pasta         | dependencies/              | Ambiente virtual (n√£o versionado)  |
| Arquivo       | .env                       | Vari√°veis de ambiente              |
| Arquivo       | main.py                    | C√≥digo principal                   |
| Arquivo       | send_to_email.py     		 | Fun√ß√£o de envio de e-mail          |
| Arquivo       | requirements.txt           | Depend√™ncias do projeto            |
| Pasta         | Output/                    | Arquivos Excel gerados             |


## Como Rodar o Projeto ?

pip install -r requirements.txt
SENDGRID_TOKEN=seu_token_sendgrid_aqui (dentro do .env)

executar

## üìà Resultado

O script ir√° gerar um arquivo Notebooks.xlsx na pasta Output, e envi√°-lo por e-mail.

O Excel gerado possui duas abas:
	- Melhores: notebooks com 100 ou mais avalia√ß√µes.
	- Piores: notebooks com menos de 100 avalia√ß√µes.

## ‚ö†Ô∏è Aten√ß√£o

- **O scraper depende da estrutura atual do site Magazine Luiza, logo, mudan√ßas no site podem exigir atualiza√ß√£o dos seletores!**
- **Nunca publique seu token de API's publicamente.** 
- **Respeite os termos de uso do site ao utilizar scraping. Consulte as [Regras da MagazineLuiza](https://www.magazineluiza.com.br/robots.txt)**

## ü§ù Contribui√ß√µes

- *Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir Issues ou enviar Pull Requests. Tamb√©m estou aprendendo :)*
